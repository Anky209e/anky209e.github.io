[ { "title": "Secure Shell Key Pairs", "url": "/posts/aws_ssh/", "categories": "AWS, Cloud, Notes", "tags": "aws, ssh, security", "date": "2022-07-03 13:10:00 +0530", "snippet": "Secure Shell Protocol(SSH)The industry-standard tool for safely encrypting remote login sessions is the Secure Shell (SSH) protocol. Without encryption, all commands and keystrokes you enter during a terminal session run over an insecure network will be easily readable by anyone with access to that network. When that “network” is the internet, that can add up to a lot of unfriendly eyes on your data.Encryption converts those plain-text data packets into what looks like gibberish. Indeed, ideally assuming no one has yet cracked the encryption algorithm you’re using—that text is and will remain gibberish, unless you happen to have the decryption key required to decrypt it. The SSH protocol manages the encryption and decryption steps in the process as long as compatible keys are present at both ends of the connection.When you launch a new EC2 Linux instance (and a heavy majority of EC2 instances are running one flavor or another of Linux), you’ll be prompted either to use an existing SSH key pair or to create a new one. Similar to access keys, you’ll get only one opportunity to download the private half of the SSH key pair to your own computer. Again, do so without publicly exposing the file.Once the private key is downloaded (and, for Linux and macOS, given appropriate permissions), you open SSH sessions to your instances by invoking the key in a connection command that might look something like this:ssh -i keyname.pem ec2-user@&lt;public_ip_address_of_instance&gt;" }, { "title": "Securing Your AWS Resources", "url": "/posts/aws_iam/", "categories": "AWS, Cloud, Notes", "tags": "aws, iam, security", "date": "2022-07-03 13:00:00 +0530", "snippet": "AWS Identity and Access ManagementWe’ll start with IAM, whose management dashboard connects you to all the administration tools you’ll need to manage the basics of account security. the Security Status section of that page provides a friendly reminder that there might be some issues requiring your attention. Those suggestions include protecting your account by locking down the root user (the user identity that was generated when you first created your AWS account) and replacing the effective functionality of root by setting up IAM users and groups for your day-to-day administration tasks.Protecting the Root UserFor practical reasons, the root user has the permissions necessary to perform any task on your account. That includes launching any resources in any region and authorizing any expenses. The problem is that actively using the root user over the long term with only minimal protections presents a significant security risk. Should the root credentials ever be compromised through an attack, there will be no limit to the potential for mischief. All your data could be stolen or deleted or the attacker could run up hundreds of thousands of dollars of charges running a rogue crypto mining operation.The recommended best practice is, therefore, to protect the root user by creating a complex password and implementing multifactor authentication and, for most administration activities, use IAM users instead. That will be covered next.AuthenticationWhether you’re logging in to work with your AWS account via the AWS Management Console, running a command from the terminal of your personal laptop, or connecting a remote application to AWS resources at the programming code level, you’ll need to prove you are who you claim to be and that “who you claim to be” has a right to the access you’re after. Often that will mean providing some kind of user ID and password. In the case of programmatic or command-line access, you’ll need a set of access keys. Opening a remotelogin session to a Linux instance on Elastic Compute Cloud (EC2) will require a valid key pair. Let’s look at those one at a time.PasswordsWhile you’re still learning your way around AWS, you’ll probably do most of your workfrom the browser’s AWS Management Console. As you’ll learn “Working with Your AWS Resources,” using the command line (specifically, AWS CLI) can be a far more efficient way to get things done, but the AWS Management Console works too.As mentioned, the fi rst step in protecting your root user is to give it a high-quality password. But that doesn’t mean you should let other users off the hook. You’ll soon see how to create such users. But before that happens, you should have an appropriate password policy already in place. You can configure a policy from the Account Settings section of the IAM Dashboard that will require the passwords used by all users on the account to conform with minimum complexity.Multi-factor authentication (MFA) adds a second layer of security to your logins. Once it’s enabled, a user will need to provide not only a password to authenticate (“somethingyou know”) but also, as a second factor, a temporary digital token sent through a present device (“something you have”), like a smartphone running an Authenticator app.Access KeysAs we mentioned, programmatic and command-line access to many AWS resources is authenticated by access keys (without the option of MFA). You can generate a new set of keys while logged into the AWS Management Console from the Security Credentials page—which is accessed from the account drop-down menu at the top right of the AWS Management Console page. Choosing the Create New Access Key button will get you there. You’ll then have the option of downloading the key to your computer as a text file or showing the actual Access Key ID and Secret Access Key values in the dialog where you can copy and paste them somewhere safe. Just make sure you choose one of those options, because you’ll never be shown the secret access key itself again. You should also remember that it’s never a good idea to expose the Secret Access Key in plain text Learn more about AWS IAM Roles Here" }, { "title": "Shared Responsibility Model:AWS", "url": "/posts/aws_responsiblity_model/", "categories": "AWS, Cloud, Notes", "tags": "aws, regions, infrastructure, online", "date": "2022-06-15 13:25:00 +0530", "snippet": "What is AWS Shared Responsibility Model?Amazon distinguishes between the security and reliability of the cloud, which is its responsibility, and the security and reliability of what’s in the cloud, which is up to you, the customerAWS is also on the hook for patching, encrypting (where relevant), and maintaining the operating systems and virtualization software running its physical servers and for the software running its managed services.But what exactly is “managed” and “unmanaged” services?Managed ResourcesA managed cloud service will “hide” all or some of the underlying configuration and administration work needed to keep things running, leaving you free to focus on the “business” end of your project. For example, an application running on an EC2 instance might need a database in the backend. You could install and configure a MySQL database engine on the instance itself, but you’d be responsible for patches, updates, and all the regular care and feeding (not to mention letting it out for its morning walks).Unmanaged ResourcesThe most obvious example of an unmanaged AWS service is EC2. When you launch an EC2 instance, you’re expected to care for the operating system and everything that’s running on it exactly the way you would for a physical server in your onpremises data center.Still, even EC2 can’t be said to be entirely unmanaged since the integrity of the physical server that hosts it is, of course, the responsibility of AWS.Service Health StatusAs part of its end of the bargain, AWS makes regularly updated, region-by-region reports on the status of its services publicly available. Any service outages that could affect the performance of anyone’s workload will appear on Amazon’s Service Health Dashboard often within a minute or two of the outage hitting.AWS Acceptable Use PolicyBecause they’re so easy to scale up, cloud computing services are powerful tools for accomplishing things no one had even dreamed of just a decade ago. But for that same reason,they’re also potential weapons that can be used to commit devastating crimes.The AWS Acceptable Use Policy makes it abundantly clear that it does not permit the use of its infrastructure in any illegal, harmful, or offensive way. Amazon reserves the right to suspend or even terminate your use of its services should you engage in illegal, insecure, or abusive activities (including the sending of spam and related mass mailings). Even running penetration testing operations against your own AWS infrastructure can cause you trouble if you don’t get explicit permission from Amazon in advance. Learn more about AWS Shared Responsibility Model" }, { "title": "Edge Locations:AWS Global Infrastructure", "url": "/posts/aws_edge/", "categories": "AWS, Cloud, Notes", "tags": "aws, egde, infrastructure, online", "date": "2022-06-15 13:20:00 +0530", "snippet": "What is a edge location?The final major piece of the AWS infrastructure puzzle is its network of edge locations. An edge location is a site where AWS deploys physical server infrastructure to provide lowlatency user access to Amazon-based dataThat definition is correct, but it does sound suspiciously like the way you’d define any other AWS data center, doesn’t it? The important difference is that your garden-variety data centers are designed to offer the full range of AWS services, including the complete set of EC2 instance types and the networking infrastructure customers would need to shape their compute environments. Edge locations, on the other hand, are much more focused on a smaller set of roles and will therefore stock a much narrower set of hardware.So, what actually happens at those edge locations? You can think of them as a front-line resource for directing the kind of network traffic that can most benefit from speed.Edge Locations and CloudFrontPerhaps the best-known tenant of edge locations is CloudFront, Amazon’s CDN service. How does that work? Let’s say you’re hosting large media fi les in S3 buckets. If users would have to retrieve their fi les directly from the bucket each time they were requested, delivery—especially to end users living continents away from the bucket location—would be relatively slow. But if you could store cached copies of the most popular fi les on servers located geographically close to your users, then they wouldn’t have to wait for the original file to be retrieved but could be enjoying the cached copy in a fraction of the time.Regional Edge Cache LocationsIn addition to the fleet of regular edge locations, Amazon has further enhanced CloudFront functionality by adding what it calls a regional edge cache. The idea is that CloudFront- served objects are maintained in edge location caches only as long as there’s a steady flow of requests. Once the rate of new requests drops off, an object will be deleted from the cache, and future requests will need to travel all the way back to the origin server (like an S3 bucket).Objects rejected by edge locations can be moved to the regional edge caches. There aren’t as many such locations worldwide, so the response times for many user requests won’t be as fast, but that’ll still probably be better than having to go all the way back to the origin. By design, regional edge cache locations are more capable of handling less-popular content." }, { "title": "Availability Zones:AWS Global Infrastructure", "url": "/posts/aws_az/", "categories": "AWS, Cloud, Notes", "tags": "aws, azs, infrastructure, online", "date": "2022-06-15 12:50:00 +0530", "snippet": "Availability Zone DesignationsUnderstanding how Availability Zones work has immediate and practical importance. Before launching an EC2 instance, for example, you’ll need to specify a network subnet associated with an AZ. It’s the subnet/AZ combination that will be your instance’s host environment. Unsure about that subnet business? You’ll learn more in just a few momentsAvailability Zone NetworkingYou’ll only get the full value out of the resources you run within an AWS Region by prop- erly organizing them into network segments (or subnets). You might, for instance, want to isolate your production servers from your development and staging servers to ensure that there’s no leakage between them. This can free your developers to confidently experiment with configuration profiles without having to worry about accidentally bringing down your public-facing application. Distributing production workloads among multiple subnets can also make your applications more highly available and fault tolerant. We’ll talk more about that in the next section.A subnet is really nothing more than a single block of Internet Protocol (IP) addresses. Any compute device that requires network connectivity must be identified by an IP address that’s unique to the network. The servers or other networked devices that are assigned an IP address within one subnet are generally able to communicate with each other by default but might have traffic coming into and/or out of the subnet restricted by firewall rules.Availability Zones and High AvailabilityOne of the key principles underlying the entire business of server administration is that all hardware (and most software) will eventually fail. It may be an important router today or a storage volume tomorrow, but nothing can last forever. And when something does break, it usually takes your application down with it. A resource running without backup is known as a single point of failure.The only effective protection against failure is redundancy, which involves provisioning two or more instances of whatever your workload requires rather than just one. That way, if one suddenly drops off the grid, a backup is there to immediately take over.You should at least be aware that AWS slays the application failure dragon using autoscaling and load balancing: Autoscaling can be configured to replace or replicate a resource to ensure that a predefined service level is maintained regardless of changes in user demand or the availability of existing resources. Load balancing orchestrates the use of multiple parallel resources to direct user requests to the server resource that’s best able to provide a successful experience. A common use case for load balancing is to coordinate the use of primary and (remote) backup resources to cover for a failure. " }, { "title": "Regions:AWS Global Infrastructure", "url": "/posts/aws_regions/", "categories": "AWS, Cloud, Notes", "tags": "aws, regions, infrastructure, online", "date": "2022-06-15 12:40:00 +0530", "snippet": "Regionally Based ServicesWhen you request an instance of an AWS service, the underlying hardware of that instance will be carved out of a server running in one—and only one—AWS Region. This is true whether you’re talking about an Elastic Compute Cloud (EC2) virtual machine instance, its Elastic Block Store (EBS) storage volume, a bucket within Simple Storage Service (S3), or a new Lambda “serverless” function. In all those cases, although that anyone anywhere in the world can be given access to your resources, their underlying physical host can exist in no more than one region.Of course, that’s not to say you can’t choose to run parallel resources in multiple regions—or that there aren’t sometimes edge-case scenarios where it makes sense to do so. But you must always be aware of the region that’s active for any resource launch you’re planning.Through no fault of the AWS designers, it’s surprisingly easy to accidentally launch a new resource into the wrong region. Checking your current region should become a second-nature reflex—much like the quick mirror checks (we hope) you regularly perform while you’re driving a carGlobally Based ServicesRemember that absolute, immutable, and fundamental law we mentioned a bit earlier about all AWS resources existing in one and only one region? Well, rest assured, dear friend, that it is indeed absolutely, immutably, and fundamentally true. Except where it isn’t. You see, some AWS resources are not visibly tied to any one region. Even if those resources are, technically, running on hardware that must exist within a single region, AWS presents them as global. As a rule, their global status will generally make sense from a structural perspective. Here are some examples of global services: AWS Identity and Access Management (IAM) is the service for managing the way access to your account resources is achieved by way of users and groups, roles, and policies. Amazon CloudFront is the content delivery network you can use to lower access latency for your application users by storing cached versions of frequently requested data at AWS edge locations.Service EndpointsTo work with or access the resources you’re running within AWS Regions, you’ll have to know how they’re identified. Your developers or administrators will, for instance, want to connect with resources through their application code or shell scripts. For such access, they’ll often authenticate into your account and list and administrate resources and objects by referring to the endpoint that’s specific to a particular region and service.For example, the correct endpoint for an EC2 instance in the us-east-1 (Northern Virginia) region would be ec2.us-east-1.amazonaws.com For up-to-date list of endpoints visit here" }, { "title": "Documentation and Online Support in AWS", "url": "/posts/aws_docs_other/", "categories": "AWS, Cloud, Notes", "tags": "aws, support, documentation, online", "date": "2022-06-13 18:29:00 +0530", "snippet": "DocumentationAWS provides a lot of documentation resources. By “a lot” we mean there’s so much of it that you’ll probably never have enough time to read through the whole thing. Instead, you’ll be better off learning how to navigate to the page containing the information you’re really after and then to the section within that page that answers your specific question.While the precise layout and organization will change over time, as of this writing the main AWS documentation page can be found at Here. There you’ll find links to more than 100 AWS services along with tutorials and projects, software development kits (SDKs), toolkits, and general resources.The AWS documentation team does a pretty good job keeping their content organized and updated. One important trick—especially if you’ve landed on a page based on the results of an internet search engine—is to look for the word latest in the web page’s URL. This tells you that you’re on the page that accurately reflects the most recent version of the software. Here’s an example of a page that includes the latest identifier:https://docs.aws.amazon.com/AmazonS3/latest/user-guide/what-is-s3.htmlKnowledge CentreThe AWS Knowledge Center is basically a frequently asked questions (FAQ) page that accidentally swallowed a family pack–sized box of steroids and then walked through the radioactive core of a nuclear power plant wearing wet pajamas. Or, in simpler terms, there’s a lot of information collected here.The Knowledge Center page contains links to nearly 1,000 questions arranged by service,each representing a fairly common problem encountered by real AWS customers. You’ll find questions like, “How can I install the AWS CloudFormation helper scripts on Ubuntu or Red Hat Enterprise Linux?” and “What happens when my reserved instance expires?” Choosing a question will take you to a page with a proposed resolution and more links to related information. If you’re ever stuck, it’s probably worth taking a quick look to see whether there’s a solution in the Knowledge Center.Security ResourcesAWS makes it perfectly clear that it wants your deployments to be as secure as possible. One way it makes this easier to accomplish is by maintaining a dedicated documentation page with links to useful and practical security-related resources. The page, found at AWS Security Resources, points to AWS blogs, white papers, articles, and tutorials covering topics such as security best practices and encrypting your data in transit and at rest.Discussion FormsWhen things don’t work the way you expected, it’s generally safe to assume you’re not the first person to hit this particular brick wall. Even if this is something only a couple dozen people have experienced, there’s a good chance that at least one of them asked about it on some online forum. While many of those questions were probably asked on Stack Overflow or another public site, the AWS discussion forums have also addressed their share of problems.The site divided into categories including Amazon Web Services (which is further divided into individual services), AWS Startups (focused on newcomers to the platform), AWS Web Site and Resources (topics like Java Development and High Performance Computing), and a number of areas serving non- English speakers using languages like Japanese and German. You can search the entire site or individual forums to see whether your question might already have been answered. To post on the forum, you’ll need to be signed into your AWS account and have a forum nickname and email.Trusted AdvisorYou use Trusted Advisor to visually confirm whether your account resource configurations are sound and are compliant with best practices. Trusted Advisor organizes its compliance alerts across five categories, Cost Optimization Performance Security Fault Tolerance Service Limits The AWS Trusted Advisor alerts users to the best-practice compliance of their running account resources. Basic Support and Developer Support plan users get service limit and some security information, while Business and Enterprise customers get access to all alerts." }, { "title": "AWS Support Types", "url": "/posts/aws_support/", "categories": "AWS, Cloud, Notes", "tags": "aws, support", "date": "2022-06-13 17:30:00 +0530", "snippet": "The Basic Support PlanOn the Basic plan, you’re not paying anything beyond the regular costs of consuming AWS resources. However, for the most part, you’re given access only to publicly available documentation, including white papers, tutorials, and support forums. In addition, you’ll be able to contact customer service at any time of the day or night for account-related issues (such as bill payment).The Developer Support PlanAWS recommends the Developer Support plan for organizations running nonproduction workloads. What’s a nonproduction workload? It’s a website or application that’s still in the development stages and isn’t yet handling critical transactions or heavy traffic. In other words, it’s a workload that could fail for extended periods of time without bringing about the sudden violent end to all life as we know it.The Buisness Support PlanThe Business Support plan can meet the needs of many organizations by offering relatively fast and detailed answers to your technical questions. Is your production system down? The Business plan guarantees a response from a cloud support engineer via email, chat, or phone within one hour. Less severe issues can take longer—up to 24 hours for what AWS calls general guidance. This level of support can include help troubleshooting interoperability between AWS resources and third-party software and operating systems. For an additional fee, you can also get in-depth guidance while you’re still in your project’s design stage through Infrastructure Event Management.The Enterprise Support PlanAs you can easily tell from the price tag (starting at $15,000/month), the Enterprise plan is appropriate only for large operations whose scope is global and for whom downtime is simply unthinkable. For example, can you imagine an evening without Netflix (which is, afterall, a key AWS customer)? What does that $15,000 get you? The detail that most stands out is the technical account manager (TAM) who is assigned as a dedicated “guide and advocate” for your account. Your TAM is more than just a technical resource; the TAM becomes closely involved in your deployment, guiding your team through planning, launches, and proactive reviews all optimized using best practices. As your advocate within AWS, a TAM can open doors and make innovative solutions possible.AWS Professional ServicesSupport is also available through the AWS Professional Services organization. The professional Services team provides “offerings” detailed guides to achieving specific outcomes and work with third-party consultants from the AWS Partner Network (APN) to actively help you build your deployments. The Professional Services team also makes tech talk webinars, white papers, and blog posts publicly available. Learn more about AWS Support Plans" }, { "title": "AWS Cost Explorer", "url": "/posts/aws_cost_explorer/", "categories": "AWS, Cloud, Notes", "tags": "aws, cost, budgets", "date": "2022-06-12 17:29:00 +0530", "snippet": "Monitoring AWS CostsIn-depth deployment planning and properly configured budgets are important tools, but they’re not enough. Just like smart security professionals will build layers of firewalls, permissions, and physical controls around their application infrastructure, account administrators will also watch events from multiple perspectives. Ongoing monitoring is a key part of that mix, and that means getting to know Amazon’s Cost Explorer and its cost and usage reports.Cost ExplorerCost Explorer lets you build graphs to visualize your account’s historical and current costs. If you’re in a hurry, you can select one of the preconfigured views provided by the service (including spending over the most recent three months by service).Cost and Usage ReportsCost and usage reports are (right now, at least) accessed from the Reports link on the Billing Dashboard. You can configure reports to be created that include the full range of activity on your account, including what resources you have running and how much they’re costing you. You can control for the level of detail and enable support for Redshift and/or Amazon QuickSight (a managed, pay-per-user business intelligence tool) to handle the visualization and analysis of what can become significant volumes of data.Cost Allocation Tags Resource tags: Resource tags are often used in busy accounts to help administratorsquickly identify the purpose and owner of a particular running resource. With hundreds ofinstances, security groups, buckets, and service definitions scattered through your account,being able to instantly understand what each one is supposed to do will make it a lot easierfor you to know how you should manage it. Cost allocation tags: Cost tags are only meant to interact with billing tools and won’tshow up in the context of any other AWS resource or process. Like resource tags, costallocation tags help you efficiently identify your resources, but only for the purpose oftracking your account spending. " }, { "title": "AWS Budgets", "url": "/posts/aws_budgets/", "categories": "AWS, Cloud, Notes", "tags": "aws, billing, budgets", "date": "2022-06-12 17:25:00 +0530", "snippet": "Using AWS BudgetsAn AWS budget is a tool for tracking a specified set of events so that when a preset threshold is approached or passed, an alert—perhaps an email—is triggered. You can create one of three budget types: Cost budget to monitor costs being incurred against your account Usage budget to track particular categories of resource consumption Reservation budget to help you understand the status of any active EC2, RDS, Redshift, or Elasticache reserve instances you might haveSetting BudgetsThe budget setup process has two parts: Set the terms of your budget—meaning, what it is that you’re tracking. Define how and when you want alerts sent. Learn more about AWS Budgets" }, { "title": "AWS Free Tier", "url": "/posts/aws_free_tier/", "categories": "AWS, Cloud, Notes", "tags": "aws, freetier", "date": "2022-06-12 17:01:00 +0530", "snippet": "How AWS Free tier Works?It’s remarkable how much you can do with the Free Tier. Since, for instance, you’re allowed to run a t2.micro Elastic Cloud Compute (EC2) instance—powered by either Linux or Windows—for up to 750 hours per month, you can effectively keep a low-demand website going without interruption for your full first year. In fact, you’d be surprised how much you can get done with such a resource.You don’t have to consume those 750 Free Tier EC2 hours by running a single instance 24/7. You could instead choose to experiment with something more complex, such as a high-availability deployment involving running two or four concurrent instances for a few hours to test resilient failover architectures. As long as the total monthly hours of run time don’t exceed 750, your credit card won’t be billed.Tracking Your Free Tier UsageOf course, accidentally leaving AWS resources running—whether you’re enjoying the Free Tier or not—can cost you much more than $1.16. Firing up a synchronously replicated RDS database instance to test your new website backend and then forgetting all about it can easily cost you thousands of dollars a month. You definitely want to keep an eye or two on your account.By default, Free Tier–related email alerts are automatically sent whenever account activity approaches or has passed Free Tier limits. Besides turning them off from the Preferences page in the Billing Dashboard in the AWS Management Console, the only thing you can do about alerts is to choose a different email address. Got to Documentation to learn more." }, { "title": "Scaliblity and Elasticity in Cloud", "url": "/posts/scalablity_elasticity/", "categories": "AWS, Cloud, Notes", "tags": "aws, cloud, scalablity, elasticity, notes", "date": "2022-06-12 10:05:00 +0530", "snippet": "Scaliblity and Elasticity-A briefThe world’s largest public cloud providers can accomplish a great deal through combining the wonders of server virtualization with the power that comes from owning vast datacenters filled with racks upon racks of hardware resources. Elasticity and scalability are the two key principles through which a lot of this happens, and understanding exactly what they mean can help you optimize your design choices so you’ll get the most bang for your cloud buck.Note that there really are no precise and authoritative definitions for scalability and elasticity in the context of cloud computing—and any definitions you do see are bound to involve at least some overlap. Nevertheless, building some kind of picture in your mind of how these two principles work can be valuable.ScaliblityA scalable service will automatically grow in capacity to seamlessly meet any changes in demand. A well-designed cloud-based operation will constantly monitor the health of its application stack and respond whenever preset performance metrics might soon go unmet.The response might include automatically launching new server instances to add extra compute power to your existing cluster. But it will probably also involve prepopulating those instances with the application data and configuration settings they’ll need to actually serve your application to your clients.ElasticityYou can stretch an elastic band far beyond its resting state. But part of what makes it truly elastic is the fact that, when you let go of it, it immediately returns to its original size. The reason the word elastic is used in the names of so many AWS services (Elastic Compute Cloud, Elastic Load Balancing, Elastic Beanstalk, and so on) is because those services are built to be easily and automatically resizedGenerally, you set the maximum and minimum performance levels you want for your application, and the AWS service(s) you’re using will automatically add or remove resources to meet changing usage demands. By way of illustration, a scalable ecommerce website could be configured to function using just a single server during low-demand periods, but any number of additional servers could be automatically brought online as demand spikes. When demand drops back down, unused servers will be shut down automatically." }, { "title": "Serverless Workloads and AWS Lambda", "url": "/posts/serverless_workload/", "categories": "AWS, Cloud, Notes", "tags": "aws, serverless, workloads, notes, awslambda", "date": "2022-06-12 09:57:00 +0530", "snippet": "Serverless WorkloadsBesides doing an excellent job emulating traditional server behavior, cloud providers can also enable entirely new ways to administrate applications and data. Perhaps the most obvious example is serverless computing.Now don’t be fooled by the name. You can’t run a compute function without a computer environment (a “server”) somewhere that’ll host it. What “serverless” does allow is for individual developers to run their code for seconds or minutes at a time on some else’s cloud servers.The serverless model—as provided by services like AWS Lambda—makes it possible to design code that reacts to external events. When, for instance, a video file is uploaded to a repository (like an AWS S3 bucket or even an on-premises FTP site), it can trigger a Lambda function that will convert the file to a new video format. There’s no need to maintain and pay for an actual instance running 24/7, just for the moments your code is actually running. And there’s no administration overhead to worry about." }, { "title": "Server Virtualization", "url": "/posts/Server_virtualization/", "categories": "AWS, Cloud, Notes", "tags": "aws, cloud, virtualmachines, notes", "date": "2022-06-11 12:00:00 +0530", "snippet": "Server Virtualization in Cloud Computing.The secret sauce that lets cloud providers give their customers on-demand compute resources in such a wide range of configurations is virtualization. When you request a virtual machine (VM) with a particular processor speed, memory capacity, and storage size, AWS doesn’t send some poor engineer running through the halls of its data center looking for an available machine with exactly that profile. Rather, as you can see illustrated in Image below, AWS carves the necessary resources from larger existing devices.A 5 TB storage drive could, for instance, be divided into dozens of smaller virtual volumes, each associated with a different virtual server (or instance). And the resources of a single physical server could be invisibly shared between multiple instances. The operating systems installed on each of those instances could run, blissfully unaware that they’re actually only masters over a small subset of a much larger server environment.Advantages of virtualization.SpeedDefining, purchasing, provisioning, testing, and launching a new physical server can take months. Even a simple reboot can keep you waiting for a couple of minutes. The time lag between requesting a new cloud-based VM and logging in and getting to work can be seconds, but never more than a few minutes. Restarting a VM can some- times happen faster than you can type your login details.EfficiencyIt’s rare to find a nonvirtualized physical server that utilizes anywhere near 100 percent of its capacity. More likely, either it’ll spend its time running mostly empty or it’ll be badly overused while you wait for more capacity to come online. Multiple virtual machines, on the other hand, can be tightly packed onto a physical server running a hypervisor (a common technology for hosting VMs). When space opens up on one server, you can quickly fill it with another virtual workload." }, { "title": "Cloud Platform Model", "url": "/posts/Cloud_platform_model/", "categories": "AWS, Cloud, Notes", "tags": "aws, cloud, saas, paas, iaas, notes", "date": "2022-06-11 04:37:00 +0530", "snippet": "Cloud Models.Cloud services comes in more than one flavor.You need to decide which one is need for your project or company.Infrastructure as a Service-IAASInfrastructure as a Service (IaaS) products generally simulate the look and feel you’d get from managing physical resources. IaaS products give you direct access to a provider’s compute, storage, and networking assets. Because it’s you that’s in there playing around at the hardware level,you rather than the IaaS provider are responsible for the consequences of any bad configurations. The trade-off is that you get to closely configure every layer of your operating stack.Platform as a Service-PAASUnlike IaaS, Platform as a Service (PaaS) products simplify the process of building an application by hiding the complexity of the infrastructure that runs it. You’re given an interface through which you define the behavior and environment you want for your application.This will often include the code that will run your applicationSoftware as a Service-SAASSoftware as a Service (SaaS) products offer services meant to be accessed by end users. An easily recognizable illustration is Google’s Gmail service, which allows users to manage their email by logging in to a browser interface or through an email client (like Microsoft Outlook) that’s running locally." }, { "title": "What is cloud?", "url": "/posts/What_is_cloud/", "categories": "AWS, Cloud, Notes", "tags": "aws, cloud, whatiscloud, notes", "date": "2022-06-11 03:37:00 +0530", "snippet": "What is Cloud Computing?Using a public cloud is about using other people’s servers to run your digital workloads.In a sense, there’s no significant difference between running a software application onservers hosted in your own office versus locating it within Amazon’s infrastructure. In bothcases, you need to make sure you’ve got sufficient compute, memory, network, and storageresources. In both cases, fast deployments and avoiding over-provisioning are key goals.Advantages of Cloud Computing Highly Available and Scalable Resources Professionally Secured Infrastructure Metered Payment Model" } ]
